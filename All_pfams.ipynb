{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd28517-9823-43cc-a488-e0f6068996c6",
   "metadata": {},
   "source": [
    "### Steps to Include All PFAM Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73753043-4b56-4bcd-a649-4062fc8875fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.83\n",
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "#Importing packages\n",
    "\n",
    "import Bio\n",
    "print(Bio.__version__)\n",
    "from Bio import SeqIO  # Import SeqIO from the Bio package\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ae1de3-5590-4886-aef1-d976c80c7ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">A0A1I4YJU4_9ENTR/160-195 A0A1I4YJU4.1 PF10417.11;1-cysPrx_C;\n",
      "ALQFHEEHGEVCPAQWHKGQEGMGASPEGVAKYLSE\n",
      ">A0A261DC17_9RICK/184-418 A0A261DC17.1 PF12574.10;120_Rick_ant;\n",
      "AALVNKSIAKPEELDDLNKFRAYFENEQNKETISGLLKEDQNLKHALEQVEIAGYKNVHT\n",
      "QFAGRFSTMEWKDGGVENANGITIKKQIVRDANGHEIATLSEANHQINPPHTVQKSDGTS\n",
      "VAISNYRTIDFPIKLDNNGPMHLSLAVKDQYGKNIAASNAVYFTAHYDDAGKLIEVSSPH\n",
      "PVKFTGNSPDAVGYIEHGGKIYTLPVTQEKYRSMMQEVAKNLGQGVNISPSIESI\n",
      ">A6LL01_THEM4/23-486 A6LL01.1 PF09847.11;12TM_1;\n",
      "TVKGNFFRQILQYIIGSVPLGLIVYFFTIDLFEKIYNVDPLVARYMYLMWSSMLSLFFVI\n",
      "GFIGLGMYSLSRNEEVELLLTMPISRTVISAYQIFSATISQIYTLSFFIFISLAYFVSTN\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/final_pfams.fasta\", \"r\") as f:\n",
    "    for i in range(10):  # Display the first 10 lines\n",
    "        print(next(f).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce7a4f9-d2d0-4b3a-9765-0def4e482745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Sequences': 19450,\n",
       " 'Shortest Sequence Length': 4,\n",
       " 'Longest Sequence Length': 1818,\n",
       " 'Average Sequence Length': 153.0196915167095}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the uploaded FASTA file\n",
    "fasta_file_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/final_pfams.fasta\"\n",
    "\n",
    "# Parse the FASTA file\n",
    "fasta_records = list(SeqIO.parse(fasta_file_path, \"fasta\"))\n",
    "\n",
    "# Extract summary information\n",
    "num_sequences = len(fasta_records)\n",
    "sequence_lengths = [len(record.seq) for record in fasta_records]\n",
    "\n",
    "# Display summary statistics\n",
    "fasta_summary = {\n",
    "    \"Total Sequences\": num_sequences,\n",
    "    \"Shortest Sequence Length\": min(sequence_lengths),\n",
    "    \"Longest Sequence Length\": max(sequence_lengths),\n",
    "    \"Average Sequence Length\": sum(sequence_lengths) / num_sequences\n",
    "}\n",
    "fasta_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233a5f8c-d64c-4dea-b543-45ec6f4ec684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Sequences': 19450,\n",
       " 'Shortest Sequence Length': 4,\n",
       " 'Longest Sequence Length': 1818,\n",
       " 'Average Sequence Length': 153.0196915167095}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom FASTA parser\n",
    "def parse_fasta(file_path):\n",
    "    sequences = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        header = None\n",
    "        sequence = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):  # Header line\n",
    "                if header:\n",
    "                    sequences[header] = \"\".join(sequence)\n",
    "                header = line[1:]  # Remove \">\"\n",
    "                sequence = []\n",
    "            else:\n",
    "                sequence.append(line)\n",
    "        if header:\n",
    "            sequences[header] = \"\".join(sequence)  # Add the last sequence\n",
    "    return sequences\n",
    "\n",
    "# Parse the provided FASTA file\n",
    "fasta_data = parse_fasta(fasta_file_path)\n",
    "\n",
    "# Extract summary statistics\n",
    "num_sequences = len(fasta_data)\n",
    "sequence_lengths = [len(seq) for seq in fasta_data.values()]\n",
    "\n",
    "fasta_summary = {\n",
    "    \"Total Sequences\": num_sequences,\n",
    "    \"Shortest Sequence Length\": min(sequence_lengths),\n",
    "    \"Longest Sequence Length\": max(sequence_lengths),\n",
    "    \"Average Sequence Length\": sum(sequence_lengths) / num_sequences\n",
    "}\n",
    "fasta_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc942b1-a080-4058-836a-e8dce7b75cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Unique PFAM IDs': 19408, 'Total Index Vectors Created': 19450}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract PFAM IDs from FASTA headers and create index vectors\n",
    "def create_pfam_index_vectors(fasta_data):\n",
    "    # Extract PFAM IDs (assuming PFAM ID is part of the header, separated by whitespace or format-specific)\n",
    "    pfam_ids = [header.split()[0] for header in fasta_data.keys()]  # Adjust this split if the format differs\n",
    "\n",
    "    # Create a mapping of unique PFAM IDs to indices\n",
    "    unique_pfam_ids = sorted(set(pfam_ids))\n",
    "    pfam_to_index = {pfam_id: idx for idx, pfam_id in enumerate(unique_pfam_ids)}\n",
    "\n",
    "    # Create index vectors for sequences\n",
    "    index_vectors = [pfam_to_index[pfam_id] for pfam_id in pfam_ids]\n",
    "\n",
    "    return pfam_to_index, index_vectors\n",
    "\n",
    "# Generate PFAM index mappings and index vectors\n",
    "pfam_to_index, index_vectors = create_pfam_index_vectors(fasta_data)\n",
    "\n",
    "# Summary of results\n",
    "pfam_index_summary = {\n",
    "    \"Total Unique PFAM IDs\": len(pfam_to_index),\n",
    "    \"Total Index Vectors Created\": len(index_vectors)\n",
    "}\n",
    "pfam_index_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40af2154-17ea-4cf9-80b2-81e1153e6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of Data: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/hr2vkz5d6rsdcwsjr4bf6ydh0000gn/T/ipykernel_15751/1855876393.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pfam_embeddings = torch.load(pfam_embeddings_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the esm1b_pfam_embs.pt file\n",
    "pfam_embeddings_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/esm1b_pfam_embs.pt\"  # Replace with the actual path\n",
    "pfam_embeddings = torch.load(pfam_embeddings_path)\n",
    "\n",
    "# Inspect the structure of the loaded embeddings\n",
    "print(f\"Type of Data: {type(pfam_embeddings)}\")\n",
    "if isinstance(pfam_embeddings, dict):\n",
    "    print(f\"Number of PFAM IDs: {len(pfam_embeddings)}\")\n",
    "    sample_key = list(pfam_embeddings.keys())[0]\n",
    "    print(f\"Sample Key: {sample_key}\")\n",
    "    print(f\"Sample Embedding Shape: {pfam_embeddings[sample_key].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c533362-58a5-45d3-a680-9999dfd84d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Shape: torch.Size([19450, 1280])\n",
      "Sample Embedding (First Row): tensor([ 0.1017,  0.1174, -0.0780,  0.1481, -0.1972, -0.0667, -0.0279, -0.0513,\n",
      "        -0.0196,  0.0401])\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape and sample data from the tensor\n",
    "print(f\"Tensor Shape: {pfam_embeddings.shape}\")\n",
    "\n",
    "# View a sample embedding (e.g., the first row)\n",
    "print(f\"Sample Embedding (First Row): {pfam_embeddings[0][:10]}\")  # Print first 10 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec05e9f-76a7-44e2-b522-21ee209f59a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BGC0000001.1,Polyketide,PF02353;PF01135;PF01269;PF13489;PF01596;PF13847;PF13649;PF08241;PF00486;PF03704;PF00067;PF00196;PF13424;PF14559;PF13401;PF13191;PF00486;PF03704;PF13428;PF13424;PF07719;PF00515;PF13176;PF13432;PF14559;PF05593;PF00108;PF08545;PF08541;PF00550;PF00198;PF06500;PF12697;PF16197;PF00698;PF02801;PF14765;PF01370;PF02719;PF03435;PF00550;PF00109;PF08659;PF13561;PF00108;PF00106;PF08990;PF00109;PF16197;PF00698;PF00550;PF00108;PF02801;PF14765;PF08240;PF00107;PF13602;PF08659;PF00106;PF01370;PF08990;PF00109;PF00108;PF02801;PF16197;PF00698;PF00550;PF14246;PF00440;PF07690;PF00083;PF03209;PF00296;PF00496;PF00528;PF00528;PF13555;PF13191;PF13401;PF02463;PF13671;PF13304;PF00005;PF13481;PF08352;PF00067;PF06902;PF13459;PF13370;PF03358;PF02525;PF00561;PF00975;PF12697;PF12146;PF07859;PF13602;PF00107;PF00440'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names to verify the correct one\n",
    "print(mibig_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17946fd6-c66e-44d3-863f-12e5279ee93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [PF00749, PF00201, PF04101, PF13579, PF03033, ...\n",
      "1    [PF00755, PF08659, PF00107, PF13489, PF10294, ...\n",
      "2    [PF07690, PF06609, PF00083, PF00975, PF00550, ...\n",
      "3        [PF00135, PF10340, PF07859, PF12146, PF00975]\n",
      "4    [PF07690, PF06609, PF00083, PF00975, PF12697, ...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the column to strings and parse PFAM IDs\n",
    "pfam_column = mibig_data.iloc[:, 0].astype(str)  # Assuming PFAM data is in the first column\n",
    "pfam_strings = pfam_column.str.split(\",\", expand=True)[2]  # Extract third part (PFAM IDs)\n",
    "pfam_strings = pfam_strings.str.split(\";\")  # Split PFAM IDs by semicolon into lists\n",
    "\n",
    "# Display a sample of parsed PFAM strings\n",
    "print(pfam_strings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e10d1fa-fa88-4c95-852e-b0d43a835655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Row Embedding Shape: (217, 1280)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_row_embeddings(pfam_strings, pfam_to_index, pfam_embeddings):\n",
    "    row_embeddings = []  # List to store embeddings for each row\n",
    "\n",
    "    for pfam_ids in pfam_strings:\n",
    "        # Initialize list for embeddings\n",
    "        embeddings = []\n",
    "        for pfam_id in pfam_ids:\n",
    "            if pfam_id in pfam_to_index:\n",
    "                # Get the index for this PFAM ID\n",
    "                idx = pfam_to_index[pfam_id]\n",
    "                embeddings.append(pfam_embeddings[idx].numpy())\n",
    "            else:\n",
    "                # Handle unknown PFAM IDs with a zero vector\n",
    "                embeddings.append(np.zeros(1280))  # Shape (1280,)\n",
    "        \n",
    "        # Stack embeddings for this row\n",
    "        row_embedding = np.stack(embeddings)  # Shape (len(PFAM_ids), 1280)\n",
    "        row_embeddings.append(row_embedding)\n",
    "\n",
    "    return row_embeddings\n",
    "\n",
    "# Generate row embeddings\n",
    "row_embeddings = create_row_embeddings(pfam_strings, pfam_to_index, pfam_embeddings)\n",
    "\n",
    "# Example row embedding shape\n",
    "print(f\"Example Row Embedding Shape: {row_embeddings[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a846a8a4-0a21-4396-9d0a-3f172473cd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Embedding Shape: (217, 1280)\n",
      "Row 2 Embedding Shape: (26, 1280)\n",
      "Row 3 Embedding Shape: (71, 1280)\n",
      "Row 4 Embedding Shape: (5, 1280)\n",
      "Row 5 Embedding Shape: (72, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of embeddings for the first few rows\n",
    "for i in range(5):  # Adjust range as needed\n",
    "    print(f\"Row {i + 1} Embedding Shape: {row_embeddings[i].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d2c4f0-aed6-4253-b4db-639835ac8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Embedding Sample:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the embeddings of the first row\n",
    "print(f\"Row 1 Embedding Sample:\\n{row_embeddings[0][:5]}\")  # First 5 PFAM embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29270433-dd1a-4e31-9147-281d7c851c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0080ceb4-8ae8-4d41-a119-80d3ec26f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Row PFAM IDs: ['PF00749', 'PF00201', 'PF04101', 'PF13579', 'PF03033', 'PF00975', 'PF12697', 'PF07859', 'PF00550', 'PF08659', 'PF00106', 'PF02719', 'PF00698', 'PF16197', 'PF00108', 'PF13561', 'PF01370', 'PF16363', 'PF14765', 'PF02801', 'PF00109', 'PF08990', 'PF08659', 'PF00106', 'PF13561', 'PF01370', 'PF13460', 'PF16363', 'PF04321', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF00550', 'PF00108', 'PF08990', 'PF00550', 'PF00106', 'PF01073', 'PF13602', 'PF00107', 'PF08240', 'PF00108', 'PF08659', 'PF04321', 'PF01370', 'PF16363', 'PF00698', 'PF14765', 'PF02719', 'PF02801', 'PF00109', 'PF05368', 'PF16197', 'PF08990', 'PF00550', 'PF08659', 'PF00106', 'PF16363', 'PF02719', 'PF00698', 'PF02801', 'PF00109', 'PF00108', 'PF01370', 'PF13561', 'PF03435', 'PF16197', 'PF00550', 'PF08659', 'PF00106', 'PF13561', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF01073', 'PF01370', 'PF02719', 'PF03435', 'PF16363', 'PF14765', 'PF00108', 'PF08990', 'PF00550', 'PF08659', 'PF00106', 'PF13561', 'PF01370', 'PF02719', 'PF14765', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF00108', 'PF08659', 'PF13561', 'PF16363', 'PF00698', 'PF16197', 'PF00108', 'PF00550', 'PF00106', 'PF01073', 'PF02719', 'PF13602', 'PF00107', 'PF08240', 'PF14765', 'PF02801', 'PF01370', 'PF13460', 'PF04321', 'PF00109', 'PF08990', 'PF00106', 'PF01073', 'PF13602', 'PF00107', 'PF00108', 'PF00550', 'PF08659', 'PF16363', 'PF01370', 'PF02719', 'PF03435', 'PF16197', 'PF02801', 'PF00109', 'PF08240', 'PF14765', 'PF00698', 'PF08990', 'PF00067', 'PF04101', 'PF00201', 'PF04101', 'PF00201', 'PF13439', 'PF13579', 'PF00483', 'PF12804', 'PF02463', 'PF13191', 'PF13401', 'PF00005', 'PF13479', 'PF13555', 'PF00664', 'PF13384', 'PF00440', 'PF02796', 'PF13412', 'PF09339', 'PF00201', 'PF04101', 'PF00201', 'PF04101', 'PF13692', 'PF13579', 'PF03033', 'PF16363', 'PF01370', 'PF04321', 'PF00728', 'PF02838', 'PF14845', 'PF01041', 'PF01212', 'PF00266', 'PF01053', 'PF00155', 'PF03033', 'PF00201', 'PF04101', 'PF01041', 'PF01053', 'PF00155', 'PF00266', 'PF06722', 'PF00201', 'PF03559', 'PF00908', 'PF00201', 'PF04101', 'PF04321', 'PF02719', 'PF01370', 'PF16363', 'PF01073', 'PF07993', 'PF13460', 'PF00196', 'PF13426', 'PF00989', 'PF08448', 'PF00296', 'PF08484', 'PF13489', 'PF13847', 'PF08241', 'PF08242', 'PF13649', 'PF07021', 'PF08421', 'PF00196', 'PF08281', 'PF13424', 'PF13401', 'PF13191', 'PF00196', 'PF13432', 'PF13191', 'PF13401', 'PF00196', 'PF13191']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/hr2vkz5d6rsdcwsjr4bf6ydh0000gn/T/ipykernel_15751/602234644.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  first_row_pfams = pfam_strings[0]\n"
     ]
    }
   ],
   "source": [
    "# Get the PFAM IDs for the first row\n",
    "first_row_pfams = pfam_strings[0]\n",
    "print(f\"First Row PFAM IDs: {first_row_pfams}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80eb22d-2f6b-46d3-9fc9-b9017cb19f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a86ce94-9211-454e-b349-ce33015d39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing PFAM IDs in First Row: ['PF00749', 'PF00201', 'PF04101', 'PF13579', 'PF03033', 'PF00975', 'PF12697', 'PF07859', 'PF00550', 'PF08659', 'PF00106', 'PF02719', 'PF00698', 'PF16197', 'PF00108', 'PF13561', 'PF01370', 'PF16363', 'PF14765', 'PF02801', 'PF00109', 'PF08990', 'PF08659', 'PF00106', 'PF13561', 'PF01370', 'PF13460', 'PF16363', 'PF04321', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF00550', 'PF00108', 'PF08990', 'PF00550', 'PF00106', 'PF01073', 'PF13602', 'PF00107', 'PF08240', 'PF00108', 'PF08659', 'PF04321', 'PF01370', 'PF16363', 'PF00698', 'PF14765', 'PF02719', 'PF02801', 'PF00109', 'PF05368', 'PF16197', 'PF08990', 'PF00550', 'PF08659', 'PF00106', 'PF16363', 'PF02719', 'PF00698', 'PF02801', 'PF00109', 'PF00108', 'PF01370', 'PF13561', 'PF03435', 'PF16197', 'PF00550', 'PF08659', 'PF00106', 'PF13561', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF01073', 'PF01370', 'PF02719', 'PF03435', 'PF16363', 'PF14765', 'PF00108', 'PF08990', 'PF00550', 'PF08659', 'PF00106', 'PF13561', 'PF01370', 'PF02719', 'PF14765', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF00108', 'PF08659', 'PF13561', 'PF16363', 'PF00698', 'PF16197', 'PF00108', 'PF00550', 'PF00106', 'PF01073', 'PF02719', 'PF13602', 'PF00107', 'PF08240', 'PF14765', 'PF02801', 'PF01370', 'PF13460', 'PF04321', 'PF00109', 'PF08990', 'PF00106', 'PF01073', 'PF13602', 'PF00107', 'PF00108', 'PF00550', 'PF08659', 'PF16363', 'PF01370', 'PF02719', 'PF03435', 'PF16197', 'PF02801', 'PF00109', 'PF08240', 'PF14765', 'PF00698', 'PF08990', 'PF00067', 'PF04101', 'PF00201', 'PF04101', 'PF00201', 'PF13439', 'PF13579', 'PF00483', 'PF12804', 'PF02463', 'PF13191', 'PF13401', 'PF00005', 'PF13479', 'PF13555', 'PF00664', 'PF13384', 'PF00440', 'PF02796', 'PF13412', 'PF09339', 'PF00201', 'PF04101', 'PF00201', 'PF04101', 'PF13692', 'PF13579', 'PF03033', 'PF16363', 'PF01370', 'PF04321', 'PF00728', 'PF02838', 'PF14845', 'PF01041', 'PF01212', 'PF00266', 'PF01053', 'PF00155', 'PF03033', 'PF00201', 'PF04101', 'PF01041', 'PF01053', 'PF00155', 'PF00266', 'PF06722', 'PF00201', 'PF03559', 'PF00908', 'PF00201', 'PF04101', 'PF04321', 'PF02719', 'PF01370', 'PF16363', 'PF01073', 'PF07993', 'PF13460', 'PF00196', 'PF13426', 'PF00989', 'PF08448', 'PF00296', 'PF08484', 'PF13489', 'PF13847', 'PF08241', 'PF08242', 'PF13649', 'PF07021', 'PF08421', 'PF00196', 'PF08281', 'PF13424', 'PF13401', 'PF13191', 'PF00196', 'PF13432', 'PF13191', 'PF13401', 'PF00196', 'PF13191']\n"
     ]
    }
   ],
   "source": [
    "# Check if the PFAM IDs exist in the mapping\n",
    "missing_pfams = [pfam_id for pfam_id in first_row_pfams if pfam_id not in pfam_to_index]\n",
    "print(f\"Missing PFAM IDs in First Row: {missing_pfams}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78dbdfe8-f465-43c9-a803-81c76cd327d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Keys from pfam_to_index: ['1105L_ASFB7/10-82', '1A_PZSVT/429-597', '2B_PEBV/1-117', '2B_TAV/7-91', '3601L_ASFB7/98-310', '5054R_ASFB7/87-280', 'A0A010R8G7_9PEZI/247-784', 'A0A010RL20_9PEZI/12-130', 'A0A010RUI5_9PEZI/166-439', 'A0A010RXA2_9PEZI/404-628']\n"
     ]
    }
   ],
   "source": [
    "# Print some keys from pfam_to_index\n",
    "print(f\"Sample Keys from pfam_to_index: {list(pfam_to_index.keys())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eeeada6-7066-4d48-a1bf-69d25a6fd685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing PFAM IDs in First Row: ['PF00749', 'PF00201', 'PF04101', 'PF13579', 'PF03033', 'PF00975', 'PF12697', 'PF07859', 'PF00550', 'PF08659', 'PF00106', 'PF02719', 'PF00698', 'PF16197', 'PF00108', 'PF13561', 'PF01370', 'PF16363', 'PF14765', 'PF02801', 'PF00109', 'PF08990', 'PF08659', 'PF00106', 'PF13561', 'PF01370', 'PF13460', 'PF16363', 'PF04321', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF00550', 'PF00108', 'PF08990', 'PF00550', 'PF00106', 'PF01073', 'PF13602', 'PF00107', 'PF08240', 'PF00108', 'PF08659', 'PF04321', 'PF01370', 'PF16363', 'PF00698', 'PF14765', 'PF02719', 'PF02801', 'PF00109', 'PF05368', 'PF16197', 'PF08990', 'PF00550', 'PF08659', 'PF00106', 'PF16363', 'PF02719', 'PF00698', 'PF02801', 'PF00109', 'PF00108', 'PF01370', 'PF13561', 'PF03435', 'PF16197', 'PF00550', 'PF08659', 'PF00106', 'PF13561', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF01073', 'PF01370', 'PF02719', 'PF03435', 'PF16363', 'PF14765', 'PF00108', 'PF08990', 'PF00550', 'PF08659', 'PF00106', 'PF13561', 'PF01370', 'PF02719', 'PF14765', 'PF00698', 'PF16197', 'PF02801', 'PF00109', 'PF00108', 'PF08659', 'PF13561', 'PF16363', 'PF00698', 'PF16197', 'PF00108', 'PF00550', 'PF00106', 'PF01073', 'PF02719', 'PF13602', 'PF00107', 'PF08240', 'PF14765', 'PF02801', 'PF01370', 'PF13460', 'PF04321', 'PF00109', 'PF08990', 'PF00106', 'PF01073', 'PF13602', 'PF00107', 'PF00108', 'PF00550', 'PF08659', 'PF16363', 'PF01370', 'PF02719', 'PF03435', 'PF16197', 'PF02801', 'PF00109', 'PF08240', 'PF14765', 'PF00698', 'PF08990', 'PF00067', 'PF04101', 'PF00201', 'PF04101', 'PF00201', 'PF13439', 'PF13579', 'PF00483', 'PF12804', 'PF02463', 'PF13191', 'PF13401', 'PF00005', 'PF13479', 'PF13555', 'PF00664', 'PF13384', 'PF00440', 'PF02796', 'PF13412', 'PF09339', 'PF00201', 'PF04101', 'PF00201', 'PF04101', 'PF13692', 'PF13579', 'PF03033', 'PF16363', 'PF01370', 'PF04321', 'PF00728', 'PF02838', 'PF14845', 'PF01041', 'PF01212', 'PF00266', 'PF01053', 'PF00155', 'PF03033', 'PF00201', 'PF04101', 'PF01041', 'PF01053', 'PF00155', 'PF00266', 'PF06722', 'PF00201', 'PF03559', 'PF00908', 'PF00201', 'PF04101', 'PF04321', 'PF02719', 'PF01370', 'PF16363', 'PF01073', 'PF07993', 'PF13460', 'PF00196', 'PF13426', 'PF00989', 'PF08448', 'PF00296', 'PF08484', 'PF13489', 'PF13847', 'PF08241', 'PF08242', 'PF13649', 'PF07021', 'PF08421', 'PF00196', 'PF08281', 'PF13424', 'PF13401', 'PF13191', 'PF00196', 'PF13432', 'PF13191', 'PF13401', 'PF00196', 'PF13191']\n",
      "Number of Missing PFAM IDs: 217\n"
     ]
    }
   ],
   "source": [
    "# Check if the PFAM IDs exist in the mapping\n",
    "missing_pfams = [pfam_id for pfam_id in first_row_pfams if pfam_id not in pfam_to_index]\n",
    "print(f\"Missing PFAM IDs in First Row: {missing_pfams}\")\n",
    "print(f\"Number of Missing PFAM IDs: {len(missing_pfams)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54606237-496b-44fe-bac3-2ec52b8c5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b43f69ff-314e-4b3e-89b1-1c1f79bf5ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Keys from pfam_to_index: ['1105L_ASFB7/10-82', '1A_PZSVT/429-597', '2B_PEBV/1-117', '2B_TAV/7-91', '3601L_ASFB7/98-310', '5054R_ASFB7/87-280', 'A0A010R8G7_9PEZI/247-784', 'A0A010RL20_9PEZI/12-130', 'A0A010RUI5_9PEZI/166-439', 'A0A010RXA2_9PEZI/404-628']\n"
     ]
    }
   ],
   "source": [
    "# Print some keys from the pfam_to_index mapping\n",
    "print(f\"Sample Keys from pfam_to_index: {list(pfam_to_index.keys())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f5e3da1-6395-459f-b0a0-79aee05f9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize PFAM IDs in pfam_strings and mapping\n",
    "pfam_strings = pfam_strings.apply(lambda x: [pfam_id.strip().upper() for pfam_id in x])\n",
    "pfam_to_index = {pfam_id.strip().upper(): idx for pfam_id, idx in pfam_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ab1a0ff-4269-4e52-9acc-d7e20dd4b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_id in missing_pfams:\n",
    "    pfam_to_index[missing_id] = len(pfam_to_index)  # Assign a new index\n",
    "    pfam_embeddings = torch.cat([pfam_embeddings, torch.zeros(1, 1280)])  # Add a zero vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35f08226-fd71-45c8-b0f4-5cde01c9f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize PFAM IDs in the dataset and the mapping\n",
    "pfam_strings = pfam_strings.apply(lambda x: [pfam_id.strip().upper() for pfam_id in x])\n",
    "pfam_to_index = {pfam_id.strip().upper(): idx for pfam_id, idx in pfam_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7d861d7-f09d-4b29-b813-a2ac995f6a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing PFAM IDs after normalization: []\n",
      "Number of Missing PFAM IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check again for missing PFAM IDs after normalization\n",
    "missing_pfams = [pfam_id for pfam_id in first_row_pfams if pfam_id not in pfam_to_index]\n",
    "print(f\"Missing PFAM IDs after normalization: {missing_pfams}\")\n",
    "print(f\"Number of Missing PFAM IDs: {len(missing_pfams)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03d43f89-6da7-420e-8d2c-7382f25fcc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Embedding Shape: (217, 1280)\n",
      "Row 1 Embedding Sample:\n",
      "[[-0.13371986  0.19606242 -0.08810301 ...  0.00279715  0.03579494\n",
      "   0.12748712]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Recreate embeddings for the first row\n",
    "row_embeddings = create_row_embeddings(pfam_strings, pfam_to_index, pfam_embeddings)\n",
    "\n",
    "# Inspect the first row embeddings\n",
    "print(f\"Row 1 Embedding Shape: {row_embeddings[0].shape}\")\n",
    "print(f\"Row 1 Embedding Sample:\\n{row_embeddings[0][:5]}\")  # First 5 embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "288d8d78-56d6-4275-bb2c-cc360c9fb137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Keys from new_pfam_to_index: ['PF2', 'PF4', 'PF8', 'PF1', 'PF0', 'PF6', 'PF9', 'PF31', 'PF7', 'PF77']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Extract PFAM IDs from the keys\n",
    "new_pfam_to_index = {}\n",
    "for key, idx in pfam_to_index.items():\n",
    "    match = re.search(r\"(PF\\d+)\", key)  # Look for PFAM ID pattern\n",
    "    if match:\n",
    "        pfam_id = match.group(1)  # Extract PFAM ID\n",
    "        new_pfam_to_index[pfam_id] = idx\n",
    "\n",
    "# Print a sample of the new mapping\n",
    "print(f\"Sample Keys from new_pfam_to_index: {list(new_pfam_to_index.keys())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d33dec3-4997-480c-b7b7-90789df937a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing PFAM IDs after updating mapping: []\n",
      "Number of Missing PFAM IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Recheck missing PFAM IDs\n",
    "missing_pfams = [pfam_id for pfam_id in first_row_pfams if pfam_id not in new_pfam_to_index]\n",
    "print(f\"Missing PFAM IDs after updating mapping: {missing_pfams}\")\n",
    "print(f\"Number of Missing PFAM IDs: {len(missing_pfams)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f6ef5-747b-4df2-a075-3a99354f895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e36fab1-43c5-4111-ae77-3e55ce61c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Embedding Shape: (217, 1280)\n",
      "Row 1 Embedding Sample:\n",
      "[[-0.13371986  0.19606242 -0.08810301 ...  0.00279715  0.03579494\n",
      "   0.12748712]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate row embeddings using the updated mapping\n",
    "row_embeddings = create_row_embeddings(pfam_strings, new_pfam_to_index, pfam_embeddings)\n",
    "\n",
    "# Inspect the first row embeddings\n",
    "print(f\"Row 1 Embedding Shape: {row_embeddings[0].shape}\")\n",
    "print(f\"Row 1 Embedding Sample:\\n{row_embeddings[0][:5]}\")  # First 5 embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8fc48ed-bb6c-4b22-a004-d5033e93f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Keys from extracted_pfam_to_index: ['PF2', 'PF4', 'PF8', 'PF1', 'PF0', 'PF6', 'PF9', 'PF31', 'PF7', 'PF77']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Extract PFAM IDs from the keys (if they exist)\n",
    "extracted_pfam_to_index = {}\n",
    "for key, idx in pfam_to_index.items():\n",
    "    match = re.search(r\"(PF\\d+)\", key)  # Look for PFAM ID patterns like PF00749\n",
    "    if match:\n",
    "        pfam_id = match.group(1)\n",
    "        extracted_pfam_to_index[pfam_id] = idx\n",
    "\n",
    "# Print a sample of the new extracted mapping\n",
    "print(f\"Sample Keys from extracted_pfam_to_index: {list(extracted_pfam_to_index.keys())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57d48e4a-3bba-4226-aaf6-350c6621961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing PFAM IDs after extraction: []\n",
      "Number of Missing PFAM IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing PFAM IDs in the new mapping\n",
    "missing_pfams = [pfam_id for pfam_id in first_row_pfams if pfam_id not in extracted_pfam_to_index]\n",
    "print(f\"Missing PFAM IDs after extraction: {missing_pfams}\")\n",
    "print(f\"Number of Missing PFAM IDs: {len(missing_pfams)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e774b60f-928c-497b-ae49-2f309e7836e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Embedding Shape: (217, 1280)\n",
      "Row 1 Embedding Sample:\n",
      "[[-0.13371986  0.19606242 -0.08810301 ...  0.00279715  0.03579494\n",
      "   0.12748712]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate row embeddings using the updated mapping\n",
    "row_embeddings = create_row_embeddings(pfam_strings, extracted_pfam_to_index, pfam_embeddings)\n",
    "\n",
    "# Inspect the first row embeddings\n",
    "print(f\"Row 1 Embedding Shape: {row_embeddings[0].shape}\")\n",
    "print(f\"Row 1 Embedding Sample:\\n{row_embeddings[0][:5]}\")  # First 5 embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95289dae-e4ab-4a71-99a7-adc6024eda19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Embedding Shape: (217, 1280)\n",
      "Row 1 Embedding Sample:\n",
      "[[-0.13371986  0.19606242 -0.08810301 ...  0.00279715  0.03579494\n",
      "   0.12748712]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def create_row_embeddings_with_locations(pfam_strings, pfam_to_index, pfam_embeddings):\n",
    "    row_embeddings = []  # List to store embeddings for each row\n",
    "\n",
    "    for pfam_string in pfam_strings:\n",
    "        # Ensure pfam_string is a semicolon-separated string\n",
    "        if isinstance(pfam_string, list):  # If pfam_string is a list, join it\n",
    "            pfam_string = \";\".join(pfam_string)\n",
    "\n",
    "        # Split the PFAM_string into individual PFAM IDs with locations\n",
    "        pfam_entries = pfam_string.split(\";\")  # Assuming PFAM IDs and locations are semicolon-separated\n",
    "\n",
    "        embeddings = []\n",
    "        for entry in pfam_entries:\n",
    "            # Extract PFAM ID and domain location (if available)\n",
    "            match = re.match(r\"(?P<pfam_id>PF\\d+)(/(?P<location>\\d+-\\d+))?\", entry)\n",
    "            if match:\n",
    "                pfam_id = match.group(\"pfam_id\")\n",
    "                location = match.group(\"location\")  # Optional domain location\n",
    "\n",
    "                # Construct the key with domain location if available\n",
    "                key = f\"{pfam_id}/{location}\" if location else pfam_id\n",
    "\n",
    "                # Check if the key exists in pfam_to_index\n",
    "                if key in pfam_to_index:\n",
    "                    idx = pfam_to_index[key]\n",
    "                    embeddings.append(pfam_embeddings[idx].numpy())\n",
    "                elif pfam_id in pfam_to_index:  # Fallback to PFAM ID without location\n",
    "                    idx = pfam_to_index[pfam_id]\n",
    "                    embeddings.append(pfam_embeddings[idx].numpy())\n",
    "                else:\n",
    "                    # Handle missing keys with zero vector\n",
    "                    embeddings.append(np.zeros(1280))  # Shape (1280,)\n",
    "\n",
    "        # Stack embeddings for this row\n",
    "        row_embedding = np.stack(embeddings) if embeddings else np.zeros((0, 1280))  # Shape (len(PFAM_ids), 1280)\n",
    "        row_embeddings.append(row_embedding)\n",
    "\n",
    "    return row_embeddings\n",
    "\n",
    "# Generate row embeddings with domain location\n",
    "row_embeddings_with_locations = create_row_embeddings_with_locations(pfam_strings, pfam_to_index, pfam_embeddings)\n",
    "\n",
    "# Inspect the first row\n",
    "print(f\"Row 1 Embedding Shape: {row_embeddings_with_locations[0].shape}\")\n",
    "print(f\"Row 1 Embedding Sample:\\n{row_embeddings_with_locations[0][:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f25d1-6b96-4068-a09c-e1b5e30671d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372beec-6615-4943-9c8a-5baad52721e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cce1630-a35d-469d-80e5-16949893994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row embeddings saved successfully to 'row_embeddings_with_locations.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the embeddings using pickle\n",
    "with open(\"row_embeddings_with_locations.pkl\", \"wb\") as f:\n",
    "    pickle.dump(row_embeddings_with_locations, f)\n",
    "\n",
    "print(\"Row embeddings saved successfully to 'row_embeddings_with_locations.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbce714f-c448-46c9-a5c6-eae5ede8dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload embeddings\n",
    "with open(\"row_embeddings_with_locations.pkl\", \"rb\") as f:\n",
    "    row_embeddings_with_locations = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64a6410b-396e-4ff1-b151-c8f906acd142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6     \\\n",
      "0   -0.13372  0.196062 -0.088103 -0.003177  0.059648  0.059623 -0.231602   \n",
      "1    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "212  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "213  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "214  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "215  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "216  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         7         8         9     ...      1270      1271      1272  \\\n",
      "0   -0.008725 -0.220286 -0.158405  ...  0.530169 -0.053297 -0.140694   \n",
      "1    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "2    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "3    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "4    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "212  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "213  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "214  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "215  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "216  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "\n",
      "         1273      1274      1275      1276      1277      1278      1279  \n",
      "0   -0.065378 -0.126681  0.136352  0.144477  0.002797  0.035795  0.127487  \n",
      "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "212  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "213  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "214  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "215  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "216  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[217 rows x 1280 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming row_embeddings_with_locations is loaded\n",
    "# Convert Row 1 embeddings to a DataFrame\n",
    "row_1_embeddings_df = pd.DataFrame(row_embeddings_with_locations[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(row_1_embeddings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70847692-5b26-4fe0-a45c-1f0869c9315e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447d17e-5121-44bd-99b8-c0e8868d5d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089359ea-6a4b-4656-932a-c7845cb27199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918a8ec-9cb9-47aa-8908-ad626ced96fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172c347-6ac8-4dfa-95b0-1dc2119c49a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
