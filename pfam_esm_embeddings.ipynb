{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To create index vectors of all PFAM entries from the final_pfams.fasta file, we'll need to parse the FASTA file and extract the PFAM IDs or information of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.83\n"
     ]
    }
   ],
   "source": [
    "import Bio\n",
    "print(Bio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your FASTA file\n",
    "fasta_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/final_pfams.fasta\"\n",
    "\n",
    "# Define the output path for the PFAM index vectors\n",
    "output_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/pfam_index_vectors.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the FASTA file\n",
    "def preview_fasta(file_path, num_records=5):\n",
    "    \"\"\"\n",
    "    Preview the first few records of a FASTA file.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for i, record in enumerate(SeqIO.parse(file_path, \"fasta\")):\n",
    "        records.append((record.id, record.description, str(record.seq)))\n",
    "        if i >= num_records - 1:\n",
    "            break\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PFAM index vectors\n",
    "def create_pfam_index(fasta_file):\n",
    "    \"\"\"\n",
    "    Creates a mapping of PFAM IDs to unique indices.\n",
    "    \"\"\"\n",
    "    pfam_index = {}\n",
    "    current_index = 0\n",
    "    \n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        header = record.description\n",
    "        # Extract PFAM ID from the header\n",
    "        pfam_id = header.split()[0]  # Adjust split logic if needed\n",
    "        \n",
    "        if pfam_id not in pfam_index:\n",
    "            pfam_index[pfam_id] = current_index\n",
    "            current_index += 1\n",
    "    \n",
    "    return pfam_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PFAM index vectors to a file\n",
    "def save_pfam_index(index_dict, output_file):\n",
    "    \"\"\"\n",
    "    Saves the PFAM index mappings to a file.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for pfam_id, index in index_dict.items():\n",
    "            f.write(f\"{pfam_id}\\t{index}\\n\")\n",
    "    print(f\"PFAM index vectors saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previewing FASTA file...\n",
      "ID: A0A1I4YJU4_9ENTR/160-195\n",
      "Description: A0A1I4YJU4_9ENTR/160-195 A0A1I4YJU4.1 PF10417.11;1-cysPrx_C;\n",
      "Sequence: ALQFHEEHGEVCPAQWHKGQEGMGASPEGVAKYLSE\n",
      "\n",
      "ID: A0A261DC17_9RICK/184-418\n",
      "Description: A0A261DC17_9RICK/184-418 A0A261DC17.1 PF12574.10;120_Rick_ant;\n",
      "Sequence: AALVNKSIAKPEELDDLNKFRAYFENEQNKETISGLLKEDQNLKHALEQVEIAGYKNVHTQFAGRFSTMEWKDGGVENANGITIKKQIVRDANGHEIATLSEANHQINPPHTVQKSDGTSVAISNYRTIDFPIKLDNNGPMHLSLAVKDQYGKNIAASNAVYFTAHYDDAGKLIEVSSPHPVKFTGNSPDAVGYIEHGGKIYTLPVTQEKYRSMMQEVAKNLGQGVNISPSIESI\n",
      "\n",
      "ID: A6LL01_THEM4/23-486\n",
      "Description: A6LL01_THEM4/23-486 A6LL01.1 PF09847.11;12TM_1;\n",
      "Sequence: TVKGNFFRQILQYIIGSVPLGLIVYFFTIDLFEKIYNVDPLVARYMYLMWSSMLSLFFVIGFIGLGMYSLSRNEEVELLLTMPISRTVISAYQIFSATISQIYTLSFFIFISLAYFVSTNQNVLLGILKIVLHIWFLISFSSVIAVLIGGRTSKSFTKRFYTIVLLLSVFFYFFIIAMTDVDVSEMENLVKMFIFSTKDYNFLAWSLISNKTLGYSLISSIFLSILFLVISKKVGFEPVQVKRKERYQIAGTGSILKALFKKDLKAAIRYEQFLYFILYPLGFGIFMMFINNQGVSPIFYTIPIFTFYVAFETGILTISEVSKIEVVSTYPITFKKLMMPKLLIPVGLNFLLLLLVFVISLFFNAVSIFLVLSMIFSLLLFLMSSVLGAYYAIKSPNVKSNNTNRVFSISATFIIEGITMGLAFGIIMPLSFIIERGNSPWWVYLIFVGSLVTSFLIFVMYFRK\n",
      "\n",
      "ID: W4J1A0_PLAFP/20-242\n",
      "Description: W4J1A0_PLAFP/20-242 W4J1A0.1 PF00244.22;14-3-3;\n",
      "Sequence: YIKILNHLGSYDETVTLIKSVNVENYNFNYTESLSVGFAFKNALNVKRKEKTILENIITNEKSSEREKICAELLKSKLNTDIRSIEKNTYAVLKNKCISRTTDDKILMLYWHILGDMSRYCADTFHGTDKEKMHEKSMKSYSYALHYANKMKIPPSSPKMLELLVSWTVLHKDMNKDINYSIELAAEAFRNAIQNMHLLENDDECSKTIRILGILRDNINKWC\n",
      "\n",
      "ID: A0A501PD76_9PROT/44-151\n",
      "Description: A0A501PD76_9PROT/44-151 A0A501PD76.1 PF16998.7;17kDa_Anti_2;\n",
      "Sequence: GKAFAIAVGAVAGAVVGSSIGKSLDEADRVKMQQSAQYALESGVSGETVTWHNPDSGNYGSVTPQPAYEPEPEQYCREYQQTITVGGKTETAYGTACRQPDGTWKITN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO  # Import SeqIO from the Bio package\n",
    "\n",
    "# Define the path to your FASTA file\n",
    "fasta_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/final_pfams.fasta\"\n",
    "\n",
    "# Function to preview the FASTA file\n",
    "def preview_fasta(file_path, num_records=5):\n",
    "    \"\"\"\n",
    "    Preview the first few records of a FASTA file.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for i, record in enumerate(SeqIO.parse(file_path, \"fasta\")):\n",
    "        records.append((record.id, record.description, str(record.seq)))\n",
    "        if i >= num_records - 1:\n",
    "            break\n",
    "    return records\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Previewing FASTA file...\")\n",
    "    fasta_preview = preview_fasta(fasta_path)\n",
    "    for record in fasta_preview:\n",
    "        print(f\"ID: {record[0]}\")\n",
    "        print(f\"Description: {record[1]}\")\n",
    "        print(f\"Sequence: {record[2]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Index Vectors for PFAM IDs\n",
    "\n",
    "Extract All PFAM IDs:\n",
    "\n",
    "The extract_pfam_ids function uses a regular expression (r'PF\\d{5}') to find all PFxxxxx patterns in the headers.\n",
    "\n",
    "A set ensures that only unique IDs are retained.\n",
    "\n",
    "Create Index Vectors:\n",
    "\n",
    "The create_index_vectors function maps each unique PFAM ID to a sequential index starting from 0.\n",
    "\n",
    "Save Results:\n",
    "\n",
    "The save_index_vectors function writes the mappings to a file, with each line formatted as PFxxxxx <tab> index.\n",
    "\n",
    "### Output\n",
    "\n",
    "Console Output (Sample):\n",
    "\n",
    "Extracting all unique PFAM IDs...\n",
    "\n",
    "Creating index vectors for PFAM IDs...\n",
    "\n",
    "Saving PFAM index vectors to file...\n",
    "\n",
    "PFAM index vectors saved to /Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/pfam_index_vectors.txt\n",
    "\n",
    "Sample of PFAM index vectors:\n",
    "\n",
    "PF00001: 0\n",
    "\n",
    "PF00002: 1\n",
    "\n",
    "PF00003: 2\n",
    "\n",
    "PF00004: 3\n",
    "\n",
    "PF00005: 4\n",
    "\n",
    "PF00006: 5\n",
    "\n",
    "PF00007: 6\n",
    "\n",
    "PF00008: 7\n",
    "\n",
    "PF00009: 8\n",
    "\n",
    "PF00010: 9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all unique PFAM IDs...\n",
      "Creating index vectors for PFAM IDs...\n",
      "Saving PFAM index vectors to file...\n",
      "PFAM index vectors saved to /Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/pfam_index_vectors.txt\n",
      "Sample of PFAM index vectors:\n",
      "PF00001: 0\n",
      "PF00002: 1\n",
      "PF00003: 2\n",
      "PF00004: 3\n",
      "PF00005: 4\n",
      "PF00006: 5\n",
      "PF00007: 6\n",
      "PF00008: 7\n",
      "PF00009: 8\n",
      "PF00010: 9\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "\n",
    "# Define the path to your FASTA file\n",
    "fasta_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/final_pfams.fasta\"\n",
    "\n",
    "# Define the output path for the PFAM index vectors\n",
    "output_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/pfam_index_vectors.txt\"\n",
    "\n",
    "# Function to extract all unique PFAM IDs\n",
    "def extract_pfam_ids(fasta_file):\n",
    "    \"\"\"\n",
    "    Extracts all unique PFAM IDs (PFxxxxx) from a FASTA file.\n",
    "    \"\"\"\n",
    "    pfam_ids = set()  # Use a set to store unique PFAM IDs\n",
    "\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # Extract the header/description\n",
    "        header = record.description\n",
    "        # Use regex to find all PFxxxxx patterns in the header\n",
    "        matches = re.findall(r'PF\\d{5}', header)\n",
    "        pfam_ids.update(matches)  # Add found PFAM IDs to the set\n",
    "\n",
    "    return sorted(pfam_ids)  # Return sorted list of unique PFAM IDs\n",
    "\n",
    "# Function to create index mappings for PFAM IDs\n",
    "def create_index_vectors(pfam_ids):\n",
    "    \"\"\"\n",
    "    Maps PFAM IDs to unique indices.\n",
    "    \"\"\"\n",
    "    return {pfam_id: index for index, pfam_id in enumerate(pfam_ids)}\n",
    "\n",
    "# Function to save the index vectors to a file\n",
    "def save_index_vectors(index_dict, output_file):\n",
    "    \"\"\"\n",
    "    Saves the PFAM index mappings to a file.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for pfam_id, index in index_dict.items():\n",
    "            f.write(f\"{pfam_id}\\t{index}\\n\")\n",
    "    print(f\"PFAM index vectors saved to {output_file}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting all unique PFAM IDs...\")\n",
    "    pfam_ids = extract_pfam_ids(fasta_path)\n",
    "\n",
    "    print(\"Creating index vectors for PFAM IDs...\")\n",
    "    pfam_index_vectors = create_index_vectors(pfam_ids)\n",
    "\n",
    "    print(\"Saving PFAM index vectors to file...\")\n",
    "    save_index_vectors(pfam_index_vectors, output_path)\n",
    "\n",
    "    print(\"Sample of PFAM index vectors:\")\n",
    "    for i, (pfam_id, index) in enumerate(pfam_index_vectors.items()):\n",
    "        print(f\"{pfam_id}: {index}\")\n",
    "        if i >= 9:  # Display only the first 10 entries\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Printed Index Vectors\n",
    "\n",
    "1. Validate Unique Indices:\n",
    "\n",
    "Collect all indices (index_dict.values()).\n",
    "\n",
    "Check if the count of indices matches the count of unique indices.\n",
    "\n",
    "2. Check for Duplicates:\n",
    "\n",
    "Collect all PFAM IDs (index_dict.keys()).\n",
    "\n",
    "Ensure the count of PFAM IDs matches the count of unique PFAM IDs.\n",
    "\n",
    "3. Report Issues:\n",
    "\n",
    "If duplicates or missing values are found, they are logged for debugging.\n",
    "\n",
    "### Example Output\n",
    "\n",
    "1. Validation Passed:\n",
    "\n",
    "Validation passed: All PFAM IDs are mapped to unique indices.\n",
    "\n",
    "Validation passed: No duplicate PFAM IDs found.\n",
    "\n",
    "Overall validation passed: Index vectors are correctly mapped.\n",
    "\n",
    "2. Validation Failed:\n",
    "\n",
    "Validation failed: Duplicate indices detected.\n",
    "\n",
    "Duplicate Indices: {3, 7}\n",
    "\n",
    "Validation failed: Duplicate PFAM IDs detected.\n",
    "\n",
    "Duplicate PFAM IDs: {'PF00001', 'PF00007'}\n",
    "\n",
    "Overall validation failed: Issues found in the index mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating PFAM index vectors...\n",
      "Validation passed: All PFAM IDs are mapped to unique indices.\n",
      "Validation passed: No duplicate PFAM IDs found.\n",
      "Overall validation passed: Index vectors are correctly mapped.\n"
     ]
    }
   ],
   "source": [
    "def validate_pfam_index_vectors(index_dict):\n",
    "    \"\"\"\n",
    "    Validates the integrity of PFAM index mappings.\n",
    "    \n",
    "    Args:\n",
    "        index_dict (dict): Dictionary of PFAM IDs and their indices.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Check for duplicate indices\n",
    "    indices = list(index_dict.values())\n",
    "    unique_indices = set(indices)\n",
    "\n",
    "    if len(indices) == len(unique_indices):\n",
    "        print(\"Validation passed: All PFAM IDs are mapped to unique indices.\")\n",
    "    else:\n",
    "        print(\"Validation failed: Duplicate indices detected.\")\n",
    "        duplicate_indices = [index for index in indices if indices.count(index) > 1]\n",
    "        print(f\"Duplicate Indices: {set(duplicate_indices)}\")\n",
    "\n",
    "    # Check for missing or duplicate PFAM IDs\n",
    "    pfam_ids = list(index_dict.keys())\n",
    "    unique_pfam_ids = set(pfam_ids)\n",
    "\n",
    "    if len(pfam_ids) == len(unique_pfam_ids):\n",
    "        print(\"Validation passed: No duplicate PFAM IDs found.\")\n",
    "    else:\n",
    "        print(\"Validation failed: Duplicate PFAM IDs detected.\")\n",
    "        duplicate_ids = [pfam_id for pfam_id in pfam_ids if pfam_ids.count(pfam_id) > 1]\n",
    "        print(f\"Duplicate PFAM IDs: {set(duplicate_ids)}\")\n",
    "\n",
    "    # Report overall validation results\n",
    "    if len(indices) == len(unique_indices) and len(pfam_ids) == len(unique_pfam_ids):\n",
    "        print(\"Overall validation passed: Index vectors are correctly mapped.\")\n",
    "    else:\n",
    "        print(\"Overall validation failed: Issues found in the index mappings.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming pfam_index_vectors is the dictionary containing PFAM IDs and their indices\n",
    "    print(\"Validating PFAM index vectors...\")\n",
    "    validate_pfam_index_vectors(pfam_index_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly parse the MiBIG_complete_dataset.txt file, which currently has all data in a single column due to incorrect delimiter handling, we can explicitly specify the correct delimiter when loading the file into a DataFrame.\n",
    "\n",
    "Steps to Parse the Data Properly\n",
    "1. Identify the Correct Delimiter: Based on the review, the delimiter separating fields in our file is a comma (,).\n",
    "2. Load the Data with the Correct Delimiter: Use the sep=\",\" argument in pandas.read_csv() to parse the file correctly.\n",
    "3. Split the Semicolon-Separated PFAM Domains: Use str.split(\";\") on the PFAM_Domains column to separate the domains into a list for each row.\n",
    "4. Normalize PFAM IDs: Ensure the PFAM IDs are correctly extracted and handled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MiBIG Dataset:\n",
      "     Cluster_ID        Type                                       PFAM_Domains\n",
      "0  BGC0000001.1  Polyketide  [PF02353, PF01135, PF01269, PF13489, PF01596, ...\n",
      "1  BGC0000002.1  Polyketide  [PF00749, PF00201, PF04101, PF13579, PF03033, ...\n",
      "2  BGC0000003.1  Polyketide  [PF00755, PF08659, PF00107, PF13489, PF10294, ...\n",
      "3  BGC0000004.1  Polyketide  [PF07690, PF06609, PF00083, PF00975, PF00550, ...\n",
      "4  BGC0000005.1  Polyketide      [PF00135, PF10340, PF07859, PF12146, PF00975]\n"
     ]
    }
   ],
   "source": [
    "### Parse and Process the Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the MiBIG datasetb\n",
    "mibig_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/MiBIG_complete_dataset.txt\"\n",
    "\n",
    "# Load the dataset with the correct delimiter\n",
    "data = pd.read_csv(mibig_path, sep=\",\", header=None, names=[\"Cluster_ID\", \"Type\", \"PFAM_Domains\"])\n",
    "\n",
    "# Split the PFAM_Domains column into lists\n",
    "data[\"PFAM_Domains\"] = data[\"PFAM_Domains\"].str.split(\";\")\n",
    "\n",
    "# Preview the parsed dataset\n",
    "print(\"Parsed MiBIG Dataset:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Unique PFAM Domains\n",
    "\n",
    "Check for the total number of unique PFAM IDs in the dataset.\n",
    "This helps ensure no duplicates exist across all BGCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique PFAM IDs: 3685\n"
     ]
    }
   ],
   "source": [
    "# Flatten the PFAM_Domains column and get unique PFAM IDs\n",
    "# Drop NaN values and ensure only valid lists are processed\n",
    "unique_pfams = set([pfam for domains in data[\"PFAM_Domains\"].dropna() for pfam in domains])\n",
    "\n",
    "print(f\"Total unique PFAM IDs: {len(unique_pfams)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique PFAM IDs: 3685\n"
     ]
    }
   ],
   "source": [
    "# Ensure only rows with valid lists are processed\n",
    "unique_pfams = set([pfam for domains in data[\"PFAM_Domains\"] if isinstance(domains, list) for pfam in domains])\n",
    "\n",
    "print(f\"Total unique PFAM IDs: {len(unique_pfams)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PFAM IDs in MiBIG: 3685\n",
      "Total PFAM IDs in final_pfams.fasta: 19092\n",
      "Common PFAM IDs: 3685\n",
      "Missing PFAM IDs in final_pfams.fasta: 0\n"
     ]
    }
   ],
   "source": [
    "# Assuming pfam_index_vectors is already created from final_pfams.fasta\n",
    "indexed_pfams = set(pfam_index_vectors.keys())  # PFAM IDs from final_pfams.fasta\n",
    "\n",
    "# Verify overlap between MiBIG PFAMs and indexed PFAMs\n",
    "mibig_pfams = unique_pfams  # PFAM IDs from MiBIG dataset\n",
    "\n",
    "# Check for matches and mismatches\n",
    "common_pfams = mibig_pfams.intersection(indexed_pfams)\n",
    "missing_pfams = mibig_pfams.difference(indexed_pfams)\n",
    "\n",
    "print(f\"Total PFAM IDs in MiBIG: {len(mibig_pfams)}\")\n",
    "print(f\"Total PFAM IDs in final_pfams.fasta: {len(indexed_pfams)}\")\n",
    "print(f\"Common PFAM IDs: {len(common_pfams)}\")\n",
    "print(f\"Missing PFAM IDs in final_pfams.fasta: {len(missing_pfams)}\")\n",
    "\n",
    "# Optionally display missing PFAM IDs\n",
    "if missing_pfams:\n",
    "    print(f\"Missing PFAM IDs: {missing_pfams}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated total PFAM indices: 19092\n"
     ]
    }
   ],
   "source": [
    "# Add missing PFAM IDs to pfam_index_vectors\n",
    "next_index = max(pfam_index_vectors.values()) + 1  # Start from the next available index\n",
    "for missing_pfam in missing_pfams:\n",
    "    pfam_index_vectors[missing_pfam] = next_index\n",
    "    next_index += 1\n",
    "\n",
    "print(f\"Updated total PFAM indices: {len(pfam_index_vectors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to final_pfams.fasta\n",
    "fasta_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/final_pfams.fasta\"\n",
    "\n",
    "# Function to extract and index PFAM IDs\n",
    "def create_pfam_index(fasta_file):\n",
    "    pfam_ids = set()\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        # Extract PFAM IDs from the header using pattern matching\n",
    "        header = record.description\n",
    "        pfam_ids.update([part.split(\".\")[0] for part in header.split(\";\") if part.startswith(\"PF\")])\n",
    "    # Create index mapping\n",
    "    return {pfam_id: idx for idx, pfam_id in enumerate(sorted(pfam_ids))}\n",
    "\n",
    "# Recreate pfam_index_vectors\n",
    "pfam_index_vectors = create_pfam_index(fasta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19092 PFAM IDs from /Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/pfam_index_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "# Path to the saved index file\n",
    "index_file_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/pfam_index_vectors.txt\"\n",
    "\n",
    "# Reload PFAM index vectors\n",
    "pfam_index_vectors = {}\n",
    "with open(index_file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        pfam_id, index = line.strip().split(\"\\t\")\n",
    "        pfam_index_vectors[pfam_id] = int(index)\n",
    "\n",
    "print(f\"Loaded {len(pfam_index_vectors)} PFAM IDs from {index_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PFAM IDs in MiBIG: 3685\n",
      "Total PFAM IDs in final_pfams.fasta: 19092\n",
      "Common PFAM IDs: 3685\n",
      "Missing PFAM IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# PFAM IDs from final_pfams.fasta\n",
    "indexed_pfams = set(pfam_index_vectors.keys())  # Reloaded PFAM IDs\n",
    "\n",
    "# PFAM IDs from MiBIG dataset\n",
    "mibig_pfams = unique_pfams  # Extracted earlier from MiBIG\n",
    "\n",
    "# Calculate overlap\n",
    "common_pfams = mibig_pfams.intersection(indexed_pfams)\n",
    "missing_pfams = mibig_pfams.difference(indexed_pfams)\n",
    "\n",
    "# Display results\n",
    "print(f\"Total PFAM IDs in MiBIG: {len(mibig_pfams)}\")\n",
    "print(f\"Total PFAM IDs in final_pfams.fasta: {len(indexed_pfams)}\")\n",
    "print(f\"Common PFAM IDs: {len(common_pfams)}\")\n",
    "print(f\"Missing PFAM IDs: {len(missing_pfams)}\")\n",
    "\n",
    "# Optionally, display a sample of missing PFAM IDs\n",
    "if missing_pfams:\n",
    "    print(f\"Sample of missing PFAM IDs: {list(missing_pfams)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated total PFAM IDs: 19092\n"
     ]
    }
   ],
   "source": [
    "# Add missing PFAM IDs to the index\n",
    "next_index = max(pfam_index_vectors.values()) + 1\n",
    "for missing_pfam in missing_pfams:\n",
    "    pfam_index_vectors[missing_pfam] = next_index\n",
    "    next_index += 1\n",
    "\n",
    "print(f\"Updated total PFAM IDs: {len(pfam_index_vectors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated PFAM index vectors saved to /Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/updated_pfam_index_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "# Save updated index to file\n",
    "updated_index_file = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/updated_pfam_index_vectors.txt\"\n",
    "with open(updated_index_file, \"w\") as f:\n",
    "    for pfam_id, index in pfam_index_vectors.items():\n",
    "        f.write(f\"{pfam_id}\\t{index}\\n\")\n",
    "\n",
    "print(f\"Updated PFAM index vectors saved to {updated_index_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map MiBIG PFAM IDs to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with PFAM Indices:\n",
      "     Cluster_ID        Type  \\\n",
      "0  BGC0000001.1  Polyketide   \n",
      "1  BGC0000002.1  Polyketide   \n",
      "2  BGC0000003.1  Polyketide   \n",
      "3  BGC0000004.1  Polyketide   \n",
      "4  BGC0000005.1  Polyketide   \n",
      "\n",
      "                                        PFAM_Domains  \\\n",
      "0  [PF02353, PF01135, PF01269, PF13489, PF01596, ...   \n",
      "1  [PF00749, PF00201, PF04101, PF13579, PF03033, ...   \n",
      "2  [PF00755, PF08659, PF00107, PF13489, PF10294, ...   \n",
      "3  [PF07690, PF06609, PF00083, PF00975, PF00550, ...   \n",
      "4      [PF00135, PF10340, PF07859, PF12146, PF00975]   \n",
      "\n",
      "                                        PFAM_Indices  \n",
      "0  [2178, 1082, 1204, 12544, 1509, 12881, 12697, ...  \n",
      "1  [719, 196, 3788, 12632, 2786, 933, 11773, 7197...  \n",
      "2  [725, 7927, 104, 12544, 9464, 1149, 12881, 753...  \n",
      "3  [7035, 6070, 81, 933, 528, 13779, 670, 15177, ...  \n",
      "4                      [132, 9505, 7197, 11236, 933]  \n"
     ]
    }
   ],
   "source": [
    "# Ensure NaN values in PFAM_Domains are replaced with an empty list\n",
    "data[\"PFAM_Domains\"] = data[\"PFAM_Domains\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Map PFAM IDs to indices, skipping any missing IDs\n",
    "data[\"PFAM_Indices\"] = data[\"PFAM_Domains\"].apply(\n",
    "    lambda x: [pfam_index_vectors[pfam] for pfam in x if pfam in pfam_index_vectors]\n",
    ")\n",
    "\n",
    "# Preview the updated dataset\n",
    "print(\"Dataset with PFAM Indices:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed MiBIG dataset saved to /Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/processed_mibig_with_indices.csv\n"
     ]
    }
   ],
   "source": [
    "processed_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/processed_mibig_with_indices.csv\"\n",
    "data.to_csv(processed_path, index=False)\n",
    "print(f\"Processed MiBIG dataset saved to {processed_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of PFAM embeddings (pfam_dense): (2024, 19092)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "# Paths to MiBIG and PFAM index files\n",
    "mibig_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/processed_mibig_with_indices.csv\"\n",
    "pfam_index_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/updated_pfam_index_vectors.txt\"\n",
    "\n",
    "# Load PFAM index vectors\n",
    "pfam_index_vectors = {}\n",
    "with open(pfam_index_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        pfam_id, index = line.strip().split(\"\\t\")\n",
    "        pfam_index_vectors[pfam_id] = int(index)\n",
    "\n",
    "# Total number of PFAM domains\n",
    "num_domains = len(pfam_index_vectors)\n",
    "num_rows = 2024  \n",
    "# Create sparse matrix for PFAM embeddings\n",
    "pfam_sparse = lil_matrix((num_rows, num_domains), dtype=np.int8)\n",
    "\n",
    "# Populate the sparse matrix with PFAM indices from MiBIG\n",
    "with open(mibig_path, \"r\") as f:\n",
    "    for row_idx, line in enumerate(f):\n",
    "        parts = line.strip().split(\",\")\n",
    "        if len(parts) > 2:\n",
    "            pfam_list = parts[2].split(\";\")  \n",
    "            for pfam in pfam_list:\n",
    "                if pfam in pfam_index_vectors:\n",
    "                    pfam_sparse[row_idx, pfam_index_vectors[pfam]] = 1\n",
    "\n",
    "# Convert to dense format\n",
    "pfam_dense = pfam_sparse.toarray()\n",
    "print(f\"Shape of PFAM embeddings (pfam_dense): {pfam_dense.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(f\"Shape of PFAM embeddings (pfam_dense): {pfam_dense.shape}\")\n",
    "print(f\"Shape of ESM embeddings (esm_dense): {esm_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ESM embeddings (esm_dense): (19450, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/hr2vkz5d6rsdcwsjr4bf6ydh0000gn/T/ipykernel_27076/934687523.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  esm_embeddings = torch.load(esm_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Load ESM embeddings\n",
    "esm_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/esm1b_pfam_embs.pt\"\n",
    "esm_embeddings = torch.load(esm_path)\n",
    "esm_dense = esm_embeddings.numpy()\n",
    "\n",
    "print(f\"Shape of ESM embeddings (esm_dense): {esm_dense.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of PFAM embeddings (pfam_dense): (2024, 19092)\n",
      "Shape of ESM embeddings (esm_dense): (19450, 1280)\n",
      "Number of rows in MiBIG dataset: 2024\n",
      "Padding PFAM embeddings with 17426 rows to match ESM embeddings...\n",
      "Hybrid embedding shape: (19450, 20372)\n",
      "Hybrid embeddings saved to /Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/hybrid_pfam_esm_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Debugging shapes\n",
    "print(f\"Shape of PFAM embeddings (pfam_dense): {pfam_dense.shape}\")\n",
    "print(f\"Shape of ESM embeddings (esm_dense): {esm_dense.shape}\")\n",
    "print(f\"Number of rows in MiBIG dataset: {data.shape[0]}\")\n",
    "\n",
    "# Check for mismatched sizes\n",
    "if pfam_dense.shape[0] > esm_dense.shape[0]:\n",
    "    # Pad ESM embeddings to match PFAM embeddings\n",
    "    difference = pfam_dense.shape[0] - esm_dense.shape[0]\n",
    "    print(f\"Padding ESM embeddings with {difference} rows to match PFAM embeddings...\")\n",
    "    esm_dense = np.pad(esm_dense, ((0, difference), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "elif esm_dense.shape[0] > pfam_dense.shape[0]:\n",
    "    # Pad PFAM embeddings to match ESM embeddings\n",
    "    difference = esm_dense.shape[0] - pfam_dense.shape[0]\n",
    "    print(f\"Padding PFAM embeddings with {difference} rows to match ESM embeddings...\")\n",
    "    pfam_dense = np.pad(pfam_dense, ((0, difference), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "# Validate alignment\n",
    "assert pfam_dense.shape[0] == esm_dense.shape[0], \"PFAM and ESM embeddings still do not align after adjustment!\"\n",
    "\n",
    "# Concatenate PFAM and ESM embeddings\n",
    "hybrid_embeddings = np.hstack([pfam_dense, esm_dense])\n",
    "\n",
    "# Output results\n",
    "print(f\"Hybrid embedding shape: {hybrid_embeddings.shape}\")\n",
    "\n",
    "# Save hybrid embeddings\n",
    "output_path = \"/Users/josephtsenum/Documents/PHA6935_AI_for_Drug_Discovery/Project/hybrid_pfam_esm_embeddings.npy\"\n",
    "np.save(output_path, hybrid_embeddings)\n",
    "\n",
    "print(f\"Hybrid embeddings saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
